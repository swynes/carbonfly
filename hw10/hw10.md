hw10
================

``` r
library(tidyverse)
```

    ## Error: package or namespace load failed for 'tidyverse' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
    ##  there is no package called 'cellranger'

``` r
library(listviewer)
library(knitr)
library(glue)
library(httr)
library(jsonlite)
library(xml2)
library(purrr)
library(tidytext)
library(repurrrsive)
```

New York Times API
------------------

<https://developer.nytimes.com>

``` r
my_key<-"insert_api_key_here"
nyt_books<-GET(glue("http://api.nytimes.com/svc/books/v3/lists/names.json?api-key={my_key}"))nyt_books<-GET(glue("http://api.nytimes.com/svc/books/v3/lists/names.json?api-key={my_key}"))

status_code(nyt_books) 
```

    ## Error: <text>:2:94: unexpected symbol
    ## 1: my_key<-"insert_api_key_here"
    ## 2: nyt_books<-GET(glue("http://api.nytimes.com/svc/books/v3/lists/names.json?api-key={my_key}"))nyt_books
    ##                                                                                                 ^

So at this point I have used my api key successfully and the status code is 200 so I'm ready to proceed by converting the html file into a list.

``` r
result1 <- content(nyt_books)
```

    ## Error in inherits(x, "response"): object 'nyt_books' not found

``` r
#Explore list called result1:
nchar(result1)
```

    ## Error in nchar(result1): object 'result1' not found

``` r
class(result1) #From this I confirm that it is a list
```

    ## Error in eval(expr, envir, enclos): object 'result1' not found

``` r
length(result1) #I confirm that the list has a length of four
```

    ## Error in eval(expr, envir, enclos): object 'result1' not found

``` r
View(result1)
```

    ## Error in as.data.frame(x): object 'result1' not found

From viewing the list it seems like the sub-list "results" contains the most interesting features. I convert this list into a dataframe. Help from: <https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/>

``` r
result1.df <- do.call(what = "rbind",
                      args = lapply(result1$results, as.data.frame))
```

    ## Error in lapply(result1$results, as.data.frame): object 'result1' not found

I now have my first dataframe from NYT. The description of this data was vague, but now I can see that it is more of a table of contents for their API. I therefore go back to use a different, more interesting API. Note that this time I use query parameters built into the url by specifying that the most emailed articles must be from the science section and from time period "1".

``` r
nyt_science<-GET(glue("http://api.nytimes.com/svc/mostpopular/v2/mostemailed/Science/1.json?api-key={my_key}"))
```

    ## Error in eval(parse(text = code, keep.source = FALSE), envir): object 'my_key' not found

``` r
status_code(nyt_science) #status code works
```

    ## Error in status_code(nyt_science): object 'nyt_science' not found

``` r
science_list <- content(nyt_science)
```

    ## Error in inherits(x, "response"): object 'nyt_science' not found

``` r
View(science_list)
```

    ## Error in as.data.frame(x): object 'science_list' not found

Once again I've created a list that now needs to be converted into a dataframe. Unfortunately this time I want to access the same element from multiple nested lists. After much searching I failed to find a way to do this using apply or map functions. The following code is way too long so I'd be happy to hear of a better solution. My current work around is to pull out the desired items into many different dataframes and then perform a full join on them.

``` r
science_df <- lapply(science_list, function(x) {
  df <- data_frame(title        = science_list$results[[1]]$title,
                   byline     = science_list$results[[1]]$byline,
                   url     = science_list$results[[1]]$url,
                   abstract= science_list$results[[1]]$abstract)
}) %>% bind_rows()
```

    ## Error in lapply(science_list, function(x) {: object 'science_list' not found

``` r
science_df2 <- lapply(science_list, function(x) {
  df <- data_frame(title        = science_list$results[[2]]$title,
                   byline     = science_list$results[[2]]$byline,
                   url     = science_list$results[[2]]$url,
                   abstract= science_list$results[[2]]$abstract)
}) %>% bind_rows()
```

    ## Error in lapply(science_list, function(x) {: object 'science_list' not found

``` r
science_df3 <- lapply(science_list, function(x) {
  df <- data_frame(title        = science_list$results[[3]]$title,
                   byline     = science_list$results[[3]]$byline,
                   url     = science_list$results[[3]]$url,
                   abstract= science_list$results[[3]]$abstract)
}) %>% bind_rows()
```

    ## Error in lapply(science_list, function(x) {: object 'science_list' not found

``` r
science_df4 <- lapply(science_list, function(x) {
  df <- data_frame(title        = science_list$results[[4]]$title,
                   byline     = science_list$results[[4]]$byline,
                   url     = science_list$results[[4]]$url,
                   abstract= science_list$results[[4]]$abstract)
}) %>% bind_rows() 
```

    ## Error in lapply(science_list, function(x) {: object 'science_list' not found

``` r
science_df5 <- lapply(science_list, function(x) {
  df <- data_frame(title        = science_list$results[[5]]$title,
                   byline     = science_list$results[[5]]$byline,
                   url     = science_list$results[[5]]$url,
                   abstract= science_list$results[[5]]$abstract)
}) %>% bind_rows()
```

    ## Error in lapply(science_list, function(x) {: object 'science_list' not found

``` r
science_df6 <- lapply(science_list, function(x) {
  df <- data_frame(title        = science_list$results[[6]]$title,
                   byline     = science_list$results[[6]]$byline,
                   url     = science_list$results[[6]]$url,
                   abstract= science_list$results[[6]]$abstract)
}) %>% bind_rows()
```

    ## Error in lapply(science_list, function(x) {: object 'science_list' not found

``` r
science_df7 <- lapply(science_list, function(x) {
  df <- data_frame(title        = science_list$results[[7]]$title,
                   byline     = science_list$results[[7]]$byline,
                   url     = science_list$results[[7]]$url,
                   abstract= science_list$results[[7]]$abstract)
}) %>% bind_rows()
```

    ## Error in lapply(science_list, function(x) {: object 'science_list' not found

``` r
#Join the multiple dfs
#https://stackoverflow.com/questions/8091303/simultaneously-merge-multiple-data-frames-in-a-list
library(plyr)
```

    ## 
    ## Attaching package: 'plyr'

    ## The following object is masked from 'package:purrr':
    ## 
    ##     compact

``` r
df_combine <- join_all(list(
  science_df,science_df2,science_df3,science_df4,science_df5,
  science_df6,science_df7),
  by='title', type='full')
```

    ## Error in join_all(list(science_df, science_df2, science_df3, science_df4, : object 'science_df' not found

Now remove deplucaites from the dataframe using distinct()

``` r
df_combine2 <- distinct(df_combine, title, byline, url, abstract)
```

    ## Error in distinct(df_combine, title, byline, url, abstract): could not find function "distinct"

``` r
View(df_combine2)
```

    ## Error in as.data.frame(x): object 'df_combine2' not found

Now that I have a dataframe, I make use tidytext to break the abstracts into individual words and analyze them. <https://github.com/juliasilge/tidytext/blob/master/vignettes/tidytext.Rmd> library(tidytext)

``` r
clean_abstracts <- df_combine %>% unnest_tokens(word, abstract) %>% 
  anti_join(stop_words, by = "word")
```

    ## Error in eval(lhs, parent, parent): object 'df_combine' not found

``` r
View(clean_abstracts)  
```

    ## Error in as.data.frame(x): object 'clean_abstracts' not found

``` r
typeof(clean_abstracts$word)
```

    ## Error in typeof(clean_abstracts$word): object 'clean_abstracts' not found

Make a list of the most frequently used words in the article abstracts:

``` r
common_words <- clean_abstracts %>%
  count(vars="word") %>% 
  arrange(-freq)
```

    ## Error in eval(lhs, parent, parent): object 'clean_abstracts' not found

``` r
View(common_words)
```

    ## Error in as.data.frame(x): object 'common_words' not found

So we see that this actually isn't a very interesting output. The most common word is researchers, used 8 times, and every other common word is used a max of four times. But now that I have the process down I could make use of it elsewhere to better effect.

REFLECTION
----------

This was one of the harder assignments for me. It took a long time to find an API where I did not get a 404 or 403 error in the status code. When I finally did get it to work on the NYT API it was because that API gave me an example of the code which I fiddled with.

For instance, the NYT endpoint is: "<https://api.nytimes.com/svc/>"

Then the API page for the NYT books best-sellers lists suggests adding "/lists/best-sellers/history.json" to this to access the best sellers list.

But, in between those two pieces of the URL you must add: "books/v3"

You can only find this out by using the NYT "Try it out" feature which shows the full url. Even if you tried to take that code format and apply it to another section, such as movies, you might be misled because their books api is on version 3, hence v3, whereas movies is on version 2.

Of course the other thing I found difficult was removing the title, byline, url and abstract from multiple lists, each of which was nested within several other lists. My workaround involved copying code multiple times over which I know is problematic but as this is a homework assignment and not a thesis, I ran out of time to find the best way to do it.

On the brighter side I was really excited to finally get some data out of an API as well as to use the function distinct() for the first time and the package "tidytext" which I found extremely useful!
